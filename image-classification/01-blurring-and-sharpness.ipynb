{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8acc53",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)\n",
    " \n",
    "<a href=\"https://hub.callysto.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fcallysto%2FML-exploration&branch=main&urlpath=image-classification/01-blurring-and-sharpness.ipynb&depth=1\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/callysto/curriculum-notebooks/master/open-in-callysto-button.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3e2e18-1e9b-47f6-af09-af5d5a666e74",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "\n",
    "In the previous notebook, we went over the details of how images are represented as arrays of numbers. The **pixel** is the smallest unit of measurement in digital art, and the pixel's colour is represented numerically by mixing different amounts of colour (i.e. RGB, RGBA) or black and white (i.e. grayscale). Information in the header of the image file will describe the format and the dimensions of the image, allowing the final picture to be drawn by software.\n",
    "\n",
    "Capturing, storing, and retrieving the image files is just a matter of reading this information. But what if we want to manipulate the images? For example, how does software like Photoshop, Microsoft Paint, or others change the values of the underlying numbers to produce the effects the user wants? In this notebook, we'll investigate how different techniques are implemented at the data level, and allow you to interact with the tools to modify the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e39d21-13f4-4dc5-bc41-f67db2edebf0",
   "metadata": {},
   "source": [
    "## Blurring\n",
    "\n",
    "As we talked about in the previous notebook, resolution is an important feature of an image when it comes to the detail available. Pictures with lower resolutions have fewer pixels to cover the same physical size, and therefore contain less information about what they're trying to show. If you have the same image, one with a higher resolution and one with a lower, and make them the same physical size, the difference in quality is apparent:\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f2/Resolution_illustration.png\" /></center>\n",
    "<center> <a href=\"https://en.wikipedia.org/wiki/Image_resolution\">https://en.wikipedia.org/wiki/Image_resolution </a></center><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5f1ec-c4c7-4be6-9b73-fd69162befe8",
   "metadata": {},
   "source": [
    "Blurring has a similar effect on an image: reducing the detail and making the edges less sharp. That's simple to see in the image above, as we move from right to left across the different resolutions. Lower resolution photos can be easily represented in higher resolutions (i.e. a 1x1 pixel in 50x50 would be a solid colour 2x2 pixel in 100x100), but how does blurring affect the underlying numbers? There are [many reasons why](https://www.photographygoals.com/blur-background-in-photos/) blurring might be used as a stylistic choice, so we'll dive into a few of the different types of blurring.\n",
    "\n",
    "We'll import *A Sunday Afternoon on the Island of La Grande Jatte* by Georges Seurat, a painting with significant line detail, to really highlight the effect of each filter. The image is high resolution (1280x861)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b235044-99ff-4a25-9e04-d80a2f34f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "painting = Image.open('img/A_Sunday_on_La_Grande_Jatte.jpg')\n",
    "display(painting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b3f73-d156-47e6-b438-37efb35b9351",
   "metadata": {},
   "source": [
    "### Kernels\n",
    "\n",
    "Before we jump into the techniques used by image editing software, it's important to understand *how* the manipiulations are performed. For most techniques (and all techniques in this notebook), the editing consists of a *filter* that \"slides\" across the image and modifies the values of each pixel according to the values inside the [kernel](https://en.wikipedia.org/wiki/Kernel_(image_processing)). The kernel is a matrix of values, centered on the pixel whose value is being modified, and the final value of that pixel is the product of the filter matrix and the pixels bounded by the kernel. \n",
    "\n",
    "For example, below is a 5x5 kernel of an *identity matrix*, which is a filter that would result in no change to the pixel and surrounding pixels. Applied to any 5x5 pixel section in an image, the center pixel would retain its original value and the outlying pixels would not have any input:\n",
    "\n",
    "```\n",
    "[0, 0, 0, 0, 0]\n",
    "[0, 0, 0, 0, 0]\n",
    "[0, 0, 1, 0, 0]\n",
    "[0, 0, 0, 0, 0]\n",
    "[0, 0, 0, 0, 0]\n",
    "```\n",
    "\n",
    "\n",
    "As we go over various filters, keep in mind that the kernel size is often a user-selectable value. The actual changes to the underlying pixel values are determined by the values inside the filter matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04ce99-674f-4899-9e24-05d456fe659f",
   "metadata": {},
   "source": [
    "### Mean Filter\n",
    "\n",
    "This is the simplest type of blurring, employing a kernel size selected by the user, and modifying each pixel to be the arithmetic mean of all the values within the kernel. For example, a 3x3 kernel would slide across each pixel (with the pixel at the center), and set the value of the pixel to be the mean of the 9 values inside the kernel, with each pixel **weighted equally**. In colour images, this is done independently for each colour channel, and the resulting mixed colour is used.\n",
    "\n",
    "For this kernel (and nearly all kernels), the size must be an odd number, so that the pixel to be modified lays in the center of the kernel:\n",
    "\n",
    "```\n",
    "[1, 1, 1]\n",
    "[1, 1, 1]\n",
    "[1, 1, 1]\n",
    "```\n",
    "\n",
    "In this filter, the resulting value of the center pixel is the **average of the element-wise products of the filter and the kernel**. In a mean filter, the value of each of the elements in the kernel is the same, so a simple mean of the kernel's contents will have the same result. As we'll see later though with other kernels, it's helpful to think of them as averages of products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da0554-44be-4194-8599-58ff9ebc5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel\n",
    "a1 = np.array([[1, 2, 6],\n",
    "               [3, 5, 3],\n",
    "               [7, 8, 2]])\n",
    "\n",
    "# Filter\n",
    "f1 = np.array([[1, 1, 1],\n",
    "               [1, 1, 1],\n",
    "               [1, 1, 1]])\n",
    "\n",
    "result1 = a1 * f1\n",
    "print(f'Product of mean filter and kernel:\\n{result1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc2441-5cdb-4588-b961-c5fe1e7db45e",
   "metadata": {},
   "source": [
    "Applying this to the center pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ad66d-671e-4f2e-9e7c-da0572d60cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel1 = np.mean(result1)\n",
    "print('Center pixel value:', round(pixel1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a929a9eb-5085-4192-bca8-6075f909bfe8",
   "metadata": {},
   "source": [
    "Try changing the width of the kernel below and see how the image is affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c324c1b-c351-4d22-a992-7a9a3e6cd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean filter\n",
    "# Set 'w' to determine the width of the kernel:\n",
    "\n",
    "w1 = 3\n",
    "\n",
    "###########\n",
    "if w1 % 2 == 0:\n",
    "    print('Kernel size must be an odd number!')\n",
    "else:\n",
    "    meanFilter = painting.filter(ImageFilter.BoxBlur(radius=((abs(w1)-1)/2)))\n",
    "    display(meanFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53053e-9cab-406b-9be1-1feb2a9a8c6c",
   "metadata": {},
   "source": [
    "### Gaussian Filter\n",
    "\n",
    "One of the drawbacks of a mean filter is that all the pixels inside the kernel have the same weight when contributing to the averaged pixel value. Especially in large kernels, pixels that are far from the center are likely less related to the center pixel, yet they have the same effect as pixels adjacent to the center.\n",
    "\n",
    "Gaussian filters attempt to limit this effect by weighting the pixels less when they're further away from the center. This allows nearer pixels to have a more potent impact on the filtered value, where the weights on the outlying pixels follow a *normal* (or *Gaussian*) distribution. In practice, Gaussian filters typically preserve line detail much better than mean filters. In the below example, the center pixel has a weight of 4, whereas the diagonal pixels have a weight of just 1:\n",
    "\n",
    "```\n",
    "[1, 2, 1]\n",
    "[2, 4, 2]\n",
    "[1, 2, 1]\n",
    "```\n",
    "\n",
    "Similar to the mean filter, the Gaussian filter is the average of the products of the kernel and the filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ec4d5-9910-4965-b036-b03ab123b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter\n",
    "f2 = np.array([[1, 2, 1],\n",
    "               [2, 4, 2],\n",
    "               [1, 2, 1]])\n",
    "\n",
    "# Element-wise multiplication with same kernel as mean filter\n",
    "result2 = a1 * f2\n",
    "print(f'Original kernel:\\n{a1}\\n')\n",
    "print(f'Product of Gaussian filter and kernel:\\n{result2}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be979b-d283-447a-8a78-6fe902f5d37f",
   "metadata": {},
   "source": [
    "Applying this to the center pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be5043-2e3e-41b3-a077-3478211a9c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel2 = np.mean(result2)\n",
    "print('Center pixel value:', round(pixel2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095354c5-cadd-497f-b097-4c45a1ea6c29",
   "metadata": {},
   "source": [
    "As the dropoff away from the center pixel follows a normal distribution, this kernel has an additional parameter of the *standard deviation* of the distribution. Try changing both the standard deviation (*sigma*) value and the kernel size to compare with the mean filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45cda2-8485-4f80-891b-b3ebc0075a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaussian Filter\n",
    "# Change the kernel width and sigma value to see the effect on the image:\n",
    "\n",
    "w2 = 5\n",
    "sigma2 = 5\n",
    "\n",
    "###########\n",
    "if w2 % 2 == 0:\n",
    "    print('Kernel size must be an odd number!')\n",
    "else:\n",
    "    gaussianFilter = Image.fromarray(cv2.GaussianBlur(np.array(painting), (abs(w2), abs(w2)), abs(sigma2)))\n",
    "    display(gaussianFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea6eb8-f1f9-4d00-a1ed-bd3b7470b677",
   "metadata": {},
   "source": [
    "### Median Filter\n",
    "\n",
    "As with any sampled data, pixel distributions that are described using their mean value can be quite sensitive to outliers, which the Gaussian filter limits, but does not eliminate. For all the same reasons it can be effective in a larger numerical dataset, utlizing the *median* value can be even more resistant to outliers. Instead of taking the mean of all the values in the kernel, the median filter takes, well, the median value. This has the effect of making sharp contrasts in colour stand out even more.\n",
    "\n",
    "Try it below to see how different kernel sizes compare when using the median filter, versus the mean and Gaussian filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b674ed21-fed0-4fb0-b613-96a1983047ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Median filter\n",
    "# Set 'w' to determine the width of the kernel:\n",
    "\n",
    "w3 = 3\n",
    "\n",
    "###########\n",
    "if w3 % 2 == 0:\n",
    "    print('Kernel size must be an odd number!')\n",
    "else:\n",
    "    medianFilter = painting.filter(ImageFilter.MedianFilter(abs(w3)))\n",
    "    display(medianFilter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e6972-3a63-4596-b36f-63af8ed137ad",
   "metadata": {},
   "source": [
    "## Sharpness\n",
    "\n",
    "Though there are artistic reasons why you might want to use blurring in an image, more commonly blurring is an undesirable artifact introduced when capturing the image. As we've seen above, it's simple to reduce the detail in an already detailed image, but it's much more difficult to take a blurry image and *increase* the detail. Nevertheless, clever techniques exist that can attempt to introduce clarity into images that lack it to begin with.\n",
    "\n",
    "The technique we'll look at here is referred to as [**Unsharp Masking**](https://en.wikipedia.org/wiki/Unsharp_masking). Though it has its roots in darkroom photography, it can be simply applied to digital images.\n",
    "\n",
    "Unsharping works by first applying a Gaussian blur, and then comparing the blurred image to the original. The difference between the two images (subject to some parameters we'll discuss in a second) is then added back to the original image to highlight the edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a28514-6c65-4ee0-b9ce-ce6aed7077b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image of painting to its pixel values\n",
    "paintingArr = np.array(painting)\n",
    "paintingArr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd856a7b-7609-4c02-bca2-a6f5480b231c",
   "metadata": {},
   "source": [
    "In the next step, we'll run a Gassian filter on the painting and subtract that blurred image from the original. Below is both the resulting array and the image the array represents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9bd22-770d-4592-90bf-dfd29ccb03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian filter (width=25, sigma=5) and convert resulting image to array; subtract from original\n",
    "paintingGauss = Image.fromarray(cv2.GaussianBlur(np.array(painting), (25,25), 5))\n",
    "paintingDiffArr = np.array(painting) - np.array(paintingGauss)\n",
    "display(paintingDiffArr)\n",
    "display(Image.fromarray(paintingDiffArr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f35b3-8ed4-46de-ac68-99873a9eb518",
   "metadata": {},
   "source": [
    "The new image is fairly noisy, but there are clearly some edges present that line up with colour transitions from the main painting. By smoothing the original image with the Gaussian filter, any sharp colour transitions (i.e. edges) that existed have been lessened by the filter, but still exist, and create the largest differences between the two images. \n",
    "\n",
    "By effectively highlighting the regions of an image most affected by blurring, and emphasizing those regions, an artificial sharpness can be added where previously the image would have been blurry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7faf34-987b-4dfc-8be2-da038326764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp = painting.filter(ImageFilter.UnsharpMask(25, 100, 0))\n",
    "display(sharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ff3aa-117f-43da-9cba-089c84739221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "567fc09a",
   "metadata": {},
   "source": [
    "[![Callysto.ca License](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-bottom.jpg?raw=true)](https://github.com/callysto/curriculum-notebooks/blob/master/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
