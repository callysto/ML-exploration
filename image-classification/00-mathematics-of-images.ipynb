{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d7b3db-f97b-4e91-b1a6-8e59e826f8b8",
   "metadata": {},
   "source": [
    "![Callysto.ca Banner](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-top.jpg?raw=true)\n",
    " \n",
    "<a href=\"https://hub.callysto.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fcallysto%2FML-exploration&branch=main&urlpath=image-classification/00-mathematics-of-images.ipynb&depth=1\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/callysto/curriculum-notebooks/master/open-in-callysto-button.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da74118-d3a0-4c63-8bbb-dba7f6dbb5da",
   "metadata": {},
   "source": [
    "# Mathematics of Images\n",
    "\n",
    "Throughout human history, people have used images to convey information in a much quicker and more permanent manner than speech (or later, text) could possibly convey. As they say, a picture is worth a thousand words, and we'll see that the information contained in a digital image file is much more than that.\n",
    "\n",
    "Although it might seem strange to reduce something visual down to a series of numbers, we'll show here that it can be done in a surprisingly elegant way that allows the images to be interpreted by many programs, and to be further manipulated to learn more about their contents.\n",
    "\n",
    "We'll start with the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc3427-e6d2-4fe6-8784-ae6223c4d7d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Resolution and Channels\n",
    "\n",
    "If you've spent much time around computers and digital media, you've no doubt heard the term **resolution**. Resolution describes the number of **pixels** that span a 2-dimensional image, usually described in the convention of **horizontal** x **vertical**, and a higher resolution indicates that an image (or screen) has more pixels and finer detail. At the same (physical) size, an image with higher resolution can have more detail, or be enlarged without the individual pixels being visible. The below image shows the level of detail available as the resolution of the image increases while the physical size of the image remains the same:\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f2/Resolution_illustration.png\" /></center>\n",
    "<center> <a href=\"https://en.wikipedia.org/wiki/Image_resolution\">https://en.wikipedia.org/wiki/Image_resolution</a></center><br>\n",
    "\n",
    "Resolution is a useful descriptor not just for images, but also for the screens on which they're displayed. Sometimes the resolution will be described solely by the vertical measurement (i.e. 1080), or alternatively it can be described in words (i.e. High Definition). Here are a few common resolutions you may have encountered:\n",
    "\n",
    "- 396 x 484 Apple Watch (Series 7)\n",
    "- 640 x 480 Standard Definition\n",
    "- 1920 x 1080 High Definition\n",
    "- 3840 x 2160 4K / Ultra HD\n",
    "- 7680 x 4320 8K / Full Ultra HD\n",
    "\n",
    "Yet another way to describe the resolution, often of an image-capturing device like a camera, is by describing the number of pixels the image contains. For example, an HD image has $1920 \\times 1080 = 2,073,600$ pixels, or roughly 2.0 **mega**pixels (1 megapixel = $10^6$ pixels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1bd26-0f1c-42cc-b83c-a227c382784e",
   "metadata": {},
   "source": [
    "We've talked about resolution in terms of pixels, but we haven't yet talked about *what a pixel is*. Pixels are the [smallest unit of detail available](https://en.wikipedia.org/wiki/Pixel) in a digital image, representing a single colour that can be arranged alongside other pixels to form an image. The pixel itself contains information about what colours it shows, or in some file formats, whether it's visible at all. Each piece of colour information a pixel contains is known as a **channel**. Different colour formats have a different number of channels:\n",
    "\n",
    "| Name | Description | Channels |\n",
    "| - | - | - |\n",
    "Grayscale | Black and white | 1 Channel\n",
    "RGB | Colour (Red/Green/Blue) | 3 Channels\n",
    "RGBA | Colour +  Transparency (Alpha)| 4 Channels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211378f-8ec6-4f0c-b32b-f9d7bdbff1a9",
   "metadata": {},
   "source": [
    "### Colour Depth\n",
    "\n",
    "For an [RGB image](https://www.youtube.com/watch?v=T0jzClmP2pc), each pixel would have 3 channels: one each for red, green, and blue. Each of the channels then would have a number that indicates the *intensity* of that colour, with the lowest possible value being lack of colour (black), and the highest possible value being the maximum brightness of that colour. The *range* of the values available to describe the colour is known as the **colour depth**, also sometimes referred to as the **bit depth**. Being a digital medium, using **bits** to describe the colour range is convenient, where the number of bits is the exponent *x* in $2^x$. \n",
    "\n",
    "A quick intro to bits: \n",
    "\n",
    "| Bits | Formula | Value | \n",
    "| - | - | - | \n",
    "1 | $2^1$ | 2 \n",
    "2 | $2^2$ | 4 \n",
    "4 | $2^4$ | 16 \n",
    "8 | $2^8$ | 256 \n",
    "\n",
    "<br>\n",
    "Low colour depths tend to produce images with 'blockier' transitions between colours, while higher depths preserve the smoothness of the original image. The below image shows the effect of bit depth on a single channel (grayscale) image:\n",
    "\n",
    "<center><img src=\"https://digamation.files.wordpress.com/2008/07/digamation-bit-depth1.jpg\" /></center>\n",
    "<center><a href=\"https://digamation.wordpress.com/2008/07/18/understanding-bit-depth\">https://digamation.wordpress.com/2008/07/18/understanding-bit-depth </a></center><br>\n",
    "\n",
    "There's a noticable difference in image quality as we move across colour depth in the image above. The left side of the image is 1-bit, so it has only $2^1=2$ colours available to detail the image: black and white. The result is a sharp contrast between the different sections of the image. The 4-bit colour depth produces $2^4=16$ shades of grey, including full black and full white. Lastly, the 8-bit has 256 possible values, giving a far clearer image, and is also by far the most common standard used for modern devices. Colour depths beyond 24-bit (or 8-bit per channel) have diminishing returns on their ability to preserve clarity at an increase in file size, but some image editing software (and graphics connector specifications) will support 30- or even 48-bit colour depths.\n",
    "\n",
    "In the next 24-bit RGB image, we can see a diagram representation of a single pixel within an image file. While a grayscale image would only have one channel, the final colour of the pixels below is determined by the amount of red, green, and blue, with intensity on a scale from 0 to 255:\n",
    "\n",
    "<center><img src=\"img/pixel-colour-diagram.png\" /></center><br>\n",
    "\n",
    "As 24-bit color is such a widely adopted standard, there are multiple resources where you [mix your own colours](https://www.csfieldguide.org.nz/en/interactives/rgb-mixer/) by adjusting the values of each of the RGB channels. Entering the RGB values for the individual colours above will produce the same colour as that within the pixel in the diagram.\n",
    "\n",
    "Another way to visualize the colours in an RGB pixel is by considering a cube, where each dimension is one of the 3 colours. The cube has side length 255 (for 8-bit colour) and all three colours originating at (0,0,0), which would be pure black. The point (255, 255, 255) represents pure white, and the dashed line between the two points would be a grayscale line in RGB. Shown again is the colour from the pixel in the previous image, along with the corners of the cube and what colours they represent:\n",
    "\n",
    "<center><img src=\"img/colour-cube.png\" /></center><br>\n",
    "\n",
    "Included below is a colour mixer that will allow you to play around with different 8-bit values for RGB (24-bit colour) to see what effect they have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348016c-8e93-4383-8087-b5fe4bb9d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import ipywidgets as w\n",
    "\n",
    "sliderRed = w.IntSlider(value=1, min=0, max=255, step=1, description='Red')\n",
    "sliderGreen = w.IntSlider(value=1, min=0, max=255, step=1, description='Green')\n",
    "sliderBlue = w.IntSlider(value=1, min=0, max=255, step=1, description='Blue')\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "\n",
    "def response(change):\n",
    "    with fig.batch_update():\n",
    "        colorMix=f'rgb({sliderRed.value}, {sliderGreen.value}, {sliderBlue.value})'       \n",
    "        fig.update_layout(title=f'Colour Mixer ({sliderRed.value},{sliderGreen.value},{sliderBlue.value})',\n",
    "                          plot_bgcolor=colorMix,\n",
    "                          paper_bgcolor='white',\n",
    "                          xaxis=dict(showgrid=False, visible=False),\n",
    "                          yaxis=dict(showgrid=False, visible=False))\n",
    "        \n",
    "sliderRed.observe(response, names=\"value\")\n",
    "sliderGreen.observe(response, names=\"value\")\n",
    "sliderBlue.observe(response, names=\"value\")\n",
    "response('')\n",
    "\n",
    "w.VBox([fig, sliderRed, sliderGreen, sliderBlue])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c9bde-c8b2-4b0a-b993-f1b6eb67a014",
   "metadata": {},
   "source": [
    "### Header\n",
    "\n",
    "You might also have noticed in the previous image the presence of a **header** block of code at the beginning of the file. Most data formats (not just images) will contain [some form of header](https://en.wikipedia.org/wiki/File_format#File_header) that describes what the file contains. For images, the header will contain (among other metadata):\n",
    "- File format\n",
    "- Number (and type) of channels\n",
    "- Colour depth\n",
    "- Image dimensions\n",
    "\n",
    "When you use software to open an image file, it will first read the header to understand how to interpret the file, as the data is effectively stored as one long string. By knowing the resolution (dimensions), the software knows where to end a horizontal line of the image and start a new one. Alternatively, some file formats include blocks of code after the last pixel in a row to indicate the end of a line. In the image above, the header would determine whether the resulting resolution is 1x4, 2x2, or even 4x1. The colour channel information within each pixel determines its final colour, and the software is able to render the image!\n",
    "\n",
    "This is a very simplified example of a small, monocolour image, but the process is the same for larger, more complex images. Hopefully you understand the basics of how images are stored as data before we dive into how we manipulate the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd67c9-7a46-4298-9ef4-05409f794bf7",
   "metadata": {},
   "source": [
    "## How Images are Stored as Data\n",
    "\n",
    "Now that you've seen how images are represented digitally, let's actually look at an image and bring them into the notebook. We'll do that using a few Python libraries, primarily the Pillow library, and start with the Callysto logo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71276ec-534b-48cf-a3ca-0391f807db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "callystoLogo = Image.open('img/Callysto_Icon.png')\n",
    "display(callystoLogo)\n",
    "print(f'Image resolution: {callystoLogo.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37617c22-d16f-4101-94b8-e9ebfd75147c",
   "metadata": {},
   "source": [
    "Wow that's a large image!\n",
    "\n",
    "Of course, in the graphic design world it's always more useful to start with a high-resolution image, and downscale it as necessary for the application. It's much more difficult to increase the resolution of an image without introducing some form of artifact.\n",
    "\n",
    "For our purposes, an image this size could be quite unwieldly, so we'll reduce the resolution down to 256x256. Note that the original image wasn't a square, it was approximately 5% (2361 / 2254 * 100 = 104.7%) wider than taller, so by forcing the image to a square shape we are slightly compressing it horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe7f3a-1ad1-46da-bbc9-358a959463b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logoSmall = callystoLogo.resize((256,256))\n",
    "logoSmall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e670fba-84e1-4d65-bf3b-a1270bfd9056",
   "metadata": {},
   "source": [
    "Now we know the resolution of our image, what can we learn about its colour channels? Let's see what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc333316-9092-451a-a2fe-367fb451e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logoSmall.mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130002a-0da3-4d5d-a04c-f8ac6c88f528",
   "metadata": {},
   "source": [
    "We can see that this image has 4 colour channels, one each for red, green, and blue, as well as a fourth channel for transparency (alpha). Depending on the colour scheme of the program you're using to read this notebook, the transparency might not be obvious. If you have the ability to switch back and forth between light and dark themes, you should be able to see that the background (i.e. outside the overlapping circles) will match whatever colour theme is being used by your software.\n",
    "\n",
    "The `mode` label of 'RGBA' also indicates that each channel is 8-bit depth, as per Pillow's [documentation](https://pillow.readthedocs.io/en/stable/handbook/concepts.html#modes).\n",
    "\n",
    "We can further verify this by changing the channels from 'RGBA' to 'RGB' (remains 8-bit, but dropping the transparency channel) and there should now be a noticeable background present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733db29c-88b0-4cdd-a215-0a93fe174544",
   "metadata": {},
   "outputs": [],
   "source": [
    "logoSmall.convert(mode='RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db652a9-ad9d-4af6-99e2-38977168d7a3",
   "metadata": {},
   "source": [
    "We can also average the colour channels and force the image into 8-bit grayscale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15f4e8-59d0-4534-a153-9448d1a72ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logoSmall.convert(mode='L')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a43ef-b3f5-4db4-b8f7-12425a2769b0",
   "metadata": {},
   "source": [
    "...or 1-bit black and white. Note how though pixels can only take one of two values in this image, by differing the density of the mix of black and white, the image gives the impression of more than just two colours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aacbe8-0136-4fcf-abad-0195b1db03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logoSmall.convert(mode='1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd5179-0693-4d13-a9d1-34cfcd65fbbc",
   "metadata": {},
   "source": [
    "Next up, let's take a look at what the actual underlying data looks like. Before we do that though, we're going to want to downsize our image even more to 32x32, or the resulting data won't very easy to see! We'll also drop the transparency channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd141a-dfdc-4d7b-9270-e65af7936f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "logoTiny = logoSmall.resize(size=(32,32)).convert(mode='RGB')\n",
    "logoTiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a43ee3-fa4e-473d-8e34-dc74bcee236c",
   "metadata": {},
   "source": [
    "Let's take a look at the data in the file. It might be a little difficult to interpret the resulting output, but each aspect of the image is 'grouped' with square brackets, `[ ]`. We've added extra spaces between the brackets to make the separation more obvious!\n",
    "\n",
    "Starting from inside out, you have the RGB colour values for each pixel: `[#, #, #]`\n",
    "\n",
    "Next, each row of pixels is also further grouped: `[ [#, #, #], ..., [#, #, #] ]`\n",
    "\n",
    "And finally, the rows are grouped to form a 2D matrix of the data: `[ [ [#, #, #], ..., [#, #, #] ], ..., [ [#, #, #], ..., [#, #, #] ] ]`\n",
    "\n",
    "Here's the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa6335-667c-4d0d-8ef9-0aafb7bf458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "logoArray = np.array(logoTiny)\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    display(logoArray[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e72f15-6c6d-4262-add8-739dafd13d1e",
   "metadata": {},
   "source": [
    "As you can see, the first row has only 2 unique values; either pure black (`[0, 0, 0]`), or pure white (`[255, 255, 255]`).\n",
    "\n",
    "We can slice the first row of the image to compare it to the underlying numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66c9a3-769c-416e-9a15-e5bf25667686",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = logoTiny.crop((0, 0, 32, 1))\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dfd2df-e2f7-4b49-a887-5f50ea7b48de",
   "metadata": {},
   "source": [
    "That's somewhat hard to see, so let's blow it up 16x to make it easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef50f6-b540-43fe-a420-1c5719716a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "line.resize((512,16), resample=Image.BOX) # BOX resample doesn't blend edges when upscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ddf816-0303-4f36-93aa-43956861e4c2",
   "metadata": {},
   "source": [
    "To appreciate the colour values in the logo, let's take a slice through the middle of the logo and do the same process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b1c50-41fe-45f8-a1d6-f58aac327a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(threshold=np.inf):\n",
    "    display(logoArray[15:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b764338-d495-4805-ae0e-5c6a2b2637f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "line2 = logoTiny.crop((0, 15, 32, 16))\n",
    "line2.resize((512,16), resample=Image.BOX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9f2c3-1fb4-4257-9511-04e6b11fa5fc",
   "metadata": {},
   "source": [
    "Try playing around with the colour mixer above to recreate the colours in the image slice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ac93d-c2e4-4677-9af0-a45ec75be944",
   "metadata": {},
   "source": [
    "[![Callysto.ca License](https://github.com/callysto/curriculum-notebooks/blob/master/callysto-notebook-banner-bottom.jpg?raw=true)](https://github.com/callysto/curriculum-notebooks/blob/master/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
